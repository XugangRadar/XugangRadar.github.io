---
title: "Read More..."
layout: single-portfolio
# excerpt: "<img src='/images/research/epr.png' alt=''>"
collection: research
order_number: 30
---
<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
img{
    width: 100%;
    height: auto;
}
 @font-face
	{font-family:宋体;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:黑体;
	panose-1:2 1 6 9 6 1 1 1 1 1;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:等线;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@宋体";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@等线";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@黑体";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:等线;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin:0cm;
	text-align:justify;
	text-justify:inter-ideograph;
	text-indent:21.0pt;
	font-size:10.5pt;
	font-family:"Times New Roman",serif;}
.MsoChpDefault
	{font-family:等线;}
 /* Page Definitions */
 @page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	layout-grid:15.6pt;}
div.WordSection1
	{page:WordSection1;}
-->
</style>

</head>

<body lang=ZH-CN style='word-wrap:break-word;text-justify-trim:punctuation'>

<div class=WordSection1 style='layout-grid:15.6pt'>

<table class=MsoTableGrid border=1 cellspacing=0 cellpadding=0
 style='border-collapse:collapse;border:none'>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal><span lang=EN-US><img width=554 height=54 id="图片 3"
  src="/images/research/interpretation/image001.png"></span></p>
  </td>
 </tr>
 <tr>
  <td width=25 valign=bottom style='width:18.8pt;border:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>
  </td>
  <td width=504 style='width:377.85pt;border:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-top:7.8pt;text-align:center'><b><span
  lang=EN-US style='font-size:18.5pt;font-family:"Times New Roman",serif;
  color:#4D7C2B'>High-resolution Radar Image Interpretation</span></b></p>
  </td>
  <td width=24 valign=bottom style='width:18.15pt;border:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>
  </td>
 </tr>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:none;
  background:#FDD100;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='line-height:25.0pt'><b><span lang=EN-US
  style='font-size:15.0pt;font-family:"Times New Roman",serif;color:#4D7C2B'>I.
  Unsupervised SAR/ISAR Image Target Classification</span></b></p>
  </td>
 </tr>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:none;
  border-bottom:solid #4D7C2B 3.0pt;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='text-indent:28.0pt;line-height:25.0pt'><span
  lang=EN-US style='font-size:14.0pt;font-family:"Times New Roman",serif'>Learning
  advanced semantic representations on unlabeled SAR\ISAR images with an unsupervised
  learning scheme can address the lack of labeled samples for radar recognition
  systems. Based on contrastive learning, we integrate deformable convolution
  into the main encoder of the contrastive learning model to achieve highly
  precise classification of deformation ISAR images <span style='color:red'>[1]</span>.
  Meanwhile, a linear evaluation protocol is proposed to monitor the
  unsupervised learning processing and evaluate the proposed method on the
  MSTAR dataset. We also transfer the learned knowledge from the MSTAR dataset
  to the OpenSARship dataset, which achieves better results than training from scratch<span style='color:red'>[2]</span>.</span></p>
  </td>
 </tr>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:solid #4D7C2B 3.0pt;
  border-top:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='text-align:center;layout-grid-mode:
  char'><span lang=EN-US><img width=909 height=389 id="图片 2"
  src="/images/research/interpretation/image002.jpg"></span></p>
  <p class=MsoNormal align=center style='text-align:center;layout-grid-mode:
  char'><b><span lang=EN-US style='font-size:14.0pt;font-family:"Times New Roman",serif'>Fig.
  1 The optimization flow of the encoder in CLISAR-Net[1].</span></b><span
  lang=EN-US><img width=672 height=267 id="图片 1"
  src="/images/research/interpretation/image003.jpg"></span></p>
  <p class=MsoNormal align=center style='text-align:center;line-height:25.0pt;
  layout-grid-mode:char'><b><span lang=EN-US style='font-size:14.0pt;
  font-family:"Times New Roman",serif'>Fig. 2 Efficiency of the contrastive
  learning method. (a) highly-precise classification results on a few of
  labeled train set than other supervised methods[1]. (b) The encoder can learn
  more generalized and high-level representations, making knowledge transfer
  between different datasets easier[2].</span></b></p>
  </td>
 </tr>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoListParagraph align=center style='margin-bottom:7.8pt;text-align:
  center;text-indent:0cm;line-height:25.0pt;layout-grid-mode:char'><b><span
  lang=EN-US style='font-size:16.0pt;color:#4D7C2B;background:white'>Related
  Publications</span></b></p>
  </td>
 </tr>
 <tr>
  <td width=553 colspan=3 valign=top style='width:414.8pt;border:none;
  background:#DBDBDB;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoListParagraph style='margin-left:9.9pt;text-indent:-9.9pt;
  line-height:25.0pt;layout-grid-mode:char'><span lang=EN-US style='font-size:
  14.0pt;color:black'>[1] Ni, Peishuang, Yanyang Liu, Hao Pei, Haoze Du, Haolin
  Li, and <b>Gang Xu</b>*, &quot;CLISAR-Net: A Deformation-Robust ISAR Image
  Classification Network Using Contrastive Learning, &quot; <i>Remote Sensing</i>, vol. 15, no. 1, p. 33, Dec. 2022, doi: 10.3390/rs15010033.</span></p>
  <p class=MsoListParagraph style='margin-left:9.9pt;text-indent:-9.9pt;
  line-height:25.0pt;layout-grid-mode:char'><span lang=EN-US style='font-size:
  14.0pt;color:black'>[2] Hao Pei, Mingjie Su, <b>Gang Xu</b>*, Mengdao Xing
  and Wei Hong, &quot;Self-supervised Feature Representation for SAR Image
  Target Classification Using Contrastive Learning,&quot; <i>IEEE Journal of
  Selected Topics in Applied Earth Observations and Remote Sensing</i>, Oct. 2023</span><span
  style='font-size:14.0pt;font-family:宋体;color:black'>，</span><span lang=EN-US
  style='font-size:14.0pt;color:black'>doi: 10.1109/JSTARS.2023.3321769.</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

</div>

</body>

</html>
