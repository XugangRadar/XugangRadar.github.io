---
title: "æ¯«ç±³æ³¢é›·è¾¾å…³é”®æ„ŸçŸ¥æŠ€æœ¯"
layout: single-portfolio
excerpt: "<img src='/images/research/epr.png' alt=''>"
collection: research
order_number: 30
header:
  og_image: "research/epr.png"
---
## ğŸš—è½¦è½½æ¯«ç±³æ³¢é›·è¾¾

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2019</div><img src='../images/500x300.png' alt="sym" width="30%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech: Fast, Robust and Controllable Text to Speech](https://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech.pdf) </p>
**Yi Ren**, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- FastSpeech is the first fully parallel end-to-end speech synthesis model.
- **Academic Impact**: This work is included by many famous speech synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet). Our work are promoted by more than 20 media and forums, such as [æœºå™¨ä¹‹å¿ƒ](https://mp.weixin.qq.com/s/UkFadiUBy-Ymn-zhJ95JcQ)ã€[InfoQ](https://www.infoq.cn/article/tvy7hnin8bjvlm6g0myu).
- **Industry Impact**: FastSpeech has been deployed in [Microsoft Azure TTS service](https://techcommunity.microsoft.com/t5/azure-ai/neural-text-to-speech-extends-support-to-15-more-languages-with/ba-p/1505911) and supports 49 more languages with state-of-the-art AI quality. It was also shown as a text-to-speech system acceleration example in [NVIDIA GTC2020](https://resources.nvidia.com/events/GTC2020s21420).
</div>
</div>

## ğŸ›€æ™ºèƒ½å®¶å±…
